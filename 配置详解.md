# 配置详解

本文档详细说明 API 中间层上下文控制系统的所有配置选项。

## 目录

- [配置文件结构](#配置文件结构)
- [系统配置](#系统配置)
- [存储配置](#存储配置)
- [上下文配置](#上下文配置)
- [提供商配置](#提供商配置)
- [模型映射配置](#模型映射配置)
- [环境变量](#环境变量)
- [配置示例](#配置示例)
- [最佳实践](#最佳实践)

---

## 配置文件结构

主配置文件位于 `config/config.yaml`，采用 YAML 格式。配置分为以下几个主要部分：

```yaml
system:          # 系统级配置
storage:         # 存储后端配置
context:         # 上下文管理默认配置
providers:       # API 提供商列表
model_mappings:  # 模型映射关系
```

---

## 系统配置

### system 部分

控制系统级别的行为和设置。

```yaml
system:
  port: 8000              # 服务监听端口
  log_level: INFO         # 日志级别
  session_ttl: 3600       # 会话过期时间（秒）
```

#### 配置项说明

| 配置项 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| `port` | 整数 | 8000 | HTTP 服务监听端口 |
| `log_level` | 字符串 | INFO | 日志级别：DEBUG, INFO, WARNING, ERROR, CRITICAL |
| `session_ttl` | 整数 | 3600 | 会话过期时间（秒），超时后会话将被清理 |

#### 示例

```yaml
system:
  port: 8080              # 使用 8080 端口
  log_level: DEBUG        # 开发环境使用 DEBUG 级别
  session_ttl: 7200       # 会话保持 2 小时
```

---

## 存储配置

### storage 部分

配置会话数据的存储后端。

```yaml
storage:
  type: memory            # 存储类型：memory 或 redis
  redis_url: redis://localhost:6379
  redis_db: 0
```

#### 配置项说明

| 配置项 | 类型 | 必需 | 说明 |
|--------|------|------|------|
| `type` | 字符串 | 是 | 存储类型：`memory`（内存）或 `redis` |
| `redis_url` | 字符串 | 否* | Redis 连接 URL（使用 redis 时必需） |
| `redis_db` | 整数 | 否 | Redis 数据库编号（默认：0） |

*当 `type` 为 `redis` 时必需

#### 存储类型对比

| 特性 | memory | redis |
|------|--------|-------|
| 性能 | 极快 | 快 |
| 持久化 | 否 | 是 |
| 多实例共享 | 否 | 是 |
| 适用场景 | 开发/测试 | 生产环境 |

#### 示例

**内存存储**（开发环境）：
```yaml
storage:
  type: memory
```

**Redis 存储**（生产环境）：
```yaml
storage:
  type: redis
  redis_url: redis://localhost:6379
  redis_db: 0
```

**Redis 带密码**：
```yaml
storage:
  type: redis
  redis_url: redis://:password@localhost:6379
  redis_db: 0
```

**Redis Sentinel**：
```yaml
storage:
  type: redis
  redis_url: redis+sentinel://localhost:26379/mymaster
  redis_db: 0
```

---

## 上下文配置

### context 部分

配置对话上下文管理的默认行为。这些设置可以在模型级别被覆盖。

```yaml
context:
  default_max_turns: 10           # 默认最大对话轮次
  default_max_tokens: 4000        # 默认最大 Token 数
  default_reduction_mode: truncation  # 默认缩减模式
  summarization_prompt: |         # 摘要提示词模板
    You are a conversation summarizer...
```

#### 配置项说明

| 配置项 | 类型 | 默认值 | 说明 |
|--------|------|--------|------|
| `default_max_turns` | 整数 | 10 | 保留的最大对话轮次 |
| `default_max_tokens` | 整数 | 4000 | 上下文的最大 Token 数量 |
| `default_reduction_mode` | 字符串 | truncation | 缩减策略：truncation, sliding_window, summarization |
| `summarization_prompt` | 字符串 | - | 摘要策略使用的提示词模板 |

#### 缩减模式详解

##### 1. truncation（截断）

**工作原理**：删除最早的消息，保留最近的 N 轮对话。

**优点**：
- 简单快速
- 无需额外 API 调用
- 可预测的行为

**缺点**：
- 可能丢失重要的早期信息
- 不考虑消息的重要性

**适用场景**：
- 短期对话
- 成本敏感的应用
- 不需要长期上下文的场景

**配置示例**：
```yaml
context:
  default_max_turns: 10
  default_reduction_mode: truncation
```

##### 2. sliding_window（滑动窗口）

**工作原理**：基于 Token 预算，保留最近的消息直到达到 Token 限制。

**优点**：
- 精确控制 Token 使用
- 自动适应消息长度
- 保留系统消息

**缺点**：
- Token 估算可能不完全准确
- 仍可能丢失重要信息

**适用场景**：
- 需要精确控制成本
- 消息长度变化大的场景
- Token 限制严格的模型

**配置示例**：
```yaml
context:
  default_max_tokens: 4000
  default_reduction_mode: sliding_window
```

##### 3. summarization（摘要）

**工作原理**：将旧消息摘要后存入记忆区，保留最近的完整消息。

**优点**：
- 保留重要信息
- 支持长期对话
- 智能压缩上下文

**缺点**：
- 需要额外的 API 调用
- 增加延迟
- 摘要质量依赖模型

**适用场景**：
- 长期对话
- 需要保留历史信息
- 对话质量优先于成本

**配置示例**：
```yaml
context:
  default_max_turns: 10
  default_reduction_mode: summarization
  summarization_prompt: |
    你是一个对话摘要助手。请简洁地总结以下对话，
    保留关键信息、用户意图和重要上下文。
    将摘要控制在 {max_tokens} 个 Token 以内。
    
    对话内容：
    {conversation_text}
    
    摘要：
```

#### 摘要提示词模板

摘要提示词支持以下占位符：

| 占位符 | 说明 |
|--------|------|
| `{max_tokens}` | 目标 Token 数量 |
| `{conversation_text}` | 需要摘要的对话文本 |

**自定义摘要提示词示例**：

```yaml
context:
  summarization_prompt: |
    # 角色
    你是一个专业的对话摘要专家。
    
    # 任务
    总结以下对话，提取关键信息：
    - 用户的主要问题和需求
    - 已经讨论的重要话题
    - 待解决的问题
    - 重要的决策或结论
    
    # 要求
    - 保持客观和准确
    - 使用简洁的语言
    - 控制在 {max_tokens} 个 Token 以内
    - 使用中文输出
    
    # 对话内容
    {conversation_text}
    
    # 摘要输出
```

---

## 提供商配置

### providers 部分

配置一个或多个 LLM API 提供商。

```yaml
providers:
  - name: official              # 提供商唯一标识
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}  # 支持环境变量
    timeout: 30                 # 请求超时时间（秒）
    models:                     # 该提供商支持的模型列表
      - gpt-4
      - gpt-3.5-turbo
```

#### 配置项说明

| 配置项 | 类型 | 必需 | 说明 |
|--------|------|------|------|
| `name` | 字符串 | 是 | 提供商的唯一标识符 |
| `base_url` | 字符串 | 是 | API 基础 URL |
| `api_key` | 字符串 | 是 | API 密钥（支持环境变量） |
| `timeout` | 整数 | 否 | 请求超时时间（秒，默认：30） |
| `models` | 数组 | 是 | 该提供商支持的模型列表 |

#### 环境变量替换

配置中可以使用 `${VAR_NAME}` 语法引用环境变量：

```yaml
providers:
  - name: official
    api_key: ${OPENAI_API_KEY}      # 从环境变量读取
  
  - name: proxy1
    api_key: ${PROXY1_API_KEY}      # 从环境变量读取
```

在 `.env` 文件中设置：
```bash
OPENAI_API_KEY=sk-your-openai-key
PROXY1_API_KEY=sk-your-proxy-key
```

#### 多提供商配置示例

```yaml
providers:
  # OpenAI 官方
  - name: openai
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
    timeout: 30
    models:
      - gpt-4
      - gpt-4-turbo-preview
      - gpt-3.5-turbo
  
  # Azure OpenAI
  - name: azure
    base_url: https://your-resource.openai.azure.com/openai/deployments
    api_key: ${AZURE_OPENAI_KEY}
    timeout: 60
    models:
      - gpt-4-azure
      - gpt-35-turbo-azure
  
  # 代理站点 1
  - name: proxy1
    base_url: https://api.proxy1.com/v1
    api_key: ${PROXY1_KEY}
    timeout: 45
    models:
      - claude-3-opus
      - claude-3-sonnet
      - claude-3-haiku
  
  # 代理站点 2
  - name: proxy2
    base_url: https://api.proxy2.com/v1
    api_key: ${PROXY2_KEY}
    timeout: 30
    models:
      - qwen-plus
      - qwen-turbo
      - glm-4
```

---

## 模型映射配置

### model_mappings 部分

定义模型的显示名称、实际 API 名称以及特定的上下文配置。

```yaml
model_mappings:
  - display_name: official/gpt-4      # 对外显示的名称
    provider_name: official           # 对应的提供商名称
    actual_model_name: gpt-4          # 实际的 API 模型名称
    context_config:                   # 可选：该模型的特定配置
      max_turns: 15
      max_tokens: 6000
      reduction_mode: truncation
```

#### 配置项说明

| 配置项 | 类型 | 必需 | 说明 |
|--------|------|------|------|
| `display_name` | 字符串 | 是 | 对外显示的模型名称（建议使用命名空间格式） |
| `provider_name` | 字符串 | 是 | 提供商名称（必须在 providers 中定义） |
| `actual_model_name` | 字符串 | 是 | 提供商 API 中的实际模型名称 |
| `context_config` | 对象 | 否 | 该模型的特定上下文配置（覆盖默认配置） |

#### 命名空间格式

推荐使用 `provider/model-name` 格式：

```yaml
model_mappings:
  - display_name: openai/gpt-4        # 清晰标识来源
    provider_name: openai
    actual_model_name: gpt-4
  
  - display_name: azure/gpt-4         # 同一模型，不同提供商
    provider_name: azure
    actual_model_name: gpt-4-azure
  
  - display_name: proxy1/claude-opus  # 代理站点的模型
    provider_name: proxy1
    actual_model_name: claude-3-opus-20240229
```

#### 模型特定配置

为不同模型设置不同的上下文策略：

```yaml
model_mappings:
  # GPT-4：长上下文，使用摘要
  - display_name: openai/gpt-4
    provider_name: openai
    actual_model_name: gpt-4
    context_config:
      max_turns: 20
      max_tokens: 8000
      reduction_mode: summarization
      summarization_model: gpt-3.5-turbo
      memory_zone_enabled: true
  
  # GPT-3.5：短上下文，使用截断
  - display_name: openai/gpt-3.5-turbo
    provider_name: openai
    actual_model_name: gpt-3.5-turbo
    context_config:
      max_turns: 10
      max_tokens: 4000
      reduction_mode: truncation
  
  # Claude：中等上下文，使用滑动窗口
  - display_name: proxy1/claude-opus
    provider_name: proxy1
    actual_model_name: claude-3-opus-20240229
    context_config:
      max_turns: 15
      max_tokens: 6000
      reduction_mode: sliding_window
```

#### context_config 详细说明

| 配置项 | 类型 | 说明 |
|--------|------|------|
| `max_turns` | 整数 | 该模型的最大对话轮次 |
| `max_tokens` | 整数 | 该模型的最大 Token 数 |
| `reduction_mode` | 字符串 | 缩减策略：truncation, sliding_window, summarization |
| `summarization_model` | 字符串 | 用于摘要的模型（仅 summarization 模式） |
| `memory_zone_enabled` | 布尔 | 是否启用记忆区存储摘要 |

---

## 环境变量

### .env 文件

在项目根目录创建 `.env` 文件存储敏感信息：

```bash
# 配置文件路径
MIDDLEWARE_CONFIG_PATH=config/config.yaml

# 服务配置
MIDDLEWARE_PORT=8000
MIDDLEWARE_HOST=0.0.0.0
MIDDLEWARE_LOG_LEVEL=INFO

# Redis 配置（如果使用）
REDIS_URL=redis://localhost:6379/0

# API 密钥
OPENAI_API_KEY=sk-your-openai-key-here
AZURE_OPENAI_KEY=your-azure-key-here
PROXY1_KEY=your-proxy1-key-here
PROXY2_KEY=your-proxy2-key-here

# 其他提供商密钥
ANTHROPIC_API_KEY=sk-ant-your-key
GOOGLE_API_KEY=your-google-key
```

### 环境变量优先级

1. 系统环境变量（最高优先级）
2. `.env` 文件
3. 配置文件中的默认值（最低优先级）

### Docker 环境变量

在 `docker-compose.yml` 中设置：

```yaml
services:
  middleware:
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MIDDLEWARE_LOG_LEVEL=INFO
      - REDIS_URL=redis://redis:6379/0
```

---

## 配置示例

### 示例 1：简单配置（单提供商）

适用于个人开发或测试。

```yaml
system:
  port: 8000
  log_level: INFO
  session_ttl: 3600

storage:
  type: memory

context:
  default_max_turns: 10
  default_max_tokens: 4000
  default_reduction_mode: truncation

providers:
  - name: openai
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
    timeout: 30
    models:
      - gpt-4
      - gpt-3.5-turbo

model_mappings:
  - display_name: openai/gpt-4
    provider_name: openai
    actual_model_name: gpt-4
  
  - display_name: openai/gpt-3.5-turbo
    provider_name: openai
    actual_model_name: gpt-3.5-turbo
```

### 示例 2：生产配置（多提供商 + Redis）

适用于生产环境，支持多个提供商和持久化存储。

```yaml
system:
  port: 8000
  log_level: INFO
  session_ttl: 7200  # 2 小时

storage:
  type: redis
  redis_url: redis://redis:6379
  redis_db: 0

context:
  default_max_turns: 15
  default_max_tokens: 6000
  default_reduction_mode: sliding_window
  summarization_prompt: |
    你是一个对话摘要助手。请简洁地总结以下对话，
    保留关键信息、用户意图和重要上下文。
    将摘要控制在 {max_tokens} 个 Token 以内。
    
    对话内容：
    {conversation_text}
    
    摘要：

providers:
  # OpenAI 官方
  - name: openai
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
    timeout: 30
    models:
      - gpt-4
      - gpt-4-turbo-preview
      - gpt-3.5-turbo
  
  # 代理站点 1
  - name: proxy1
    base_url: https://api.proxy1.com/v1
    api_key: ${PROXY1_KEY}
    timeout: 45
    models:
      - claude-3-opus
      - claude-3-sonnet
  
  # 代理站点 2
  - name: proxy2
    base_url: https://api.proxy2.com/v1
    api_key: ${PROXY2_KEY}
    timeout: 30
    models:
      - qwen-plus
      - glm-4

model_mappings:
  # OpenAI 模型
  - display_name: openai/gpt-4
    provider_name: openai
    actual_model_name: gpt-4
    context_config:
      max_turns: 20
      max_tokens: 8000
      reduction_mode: summarization
      summarization_model: gpt-3.5-turbo
      memory_zone_enabled: true
  
  - display_name: openai/gpt-3.5-turbo
    provider_name: openai
    actual_model_name: gpt-3.5-turbo
    context_config:
      max_turns: 10
      max_tokens: 4000
      reduction_mode: truncation
  
  # Claude 模型
  - display_name: proxy1/claude-opus
    provider_name: proxy1
    actual_model_name: claude-3-opus-20240229
    context_config:
      max_turns: 15
      max_tokens: 6000
      reduction_mode: sliding_window
  
  - display_name: proxy1/claude-sonnet
    provider_name: proxy1
    actual_model_name: claude-3-sonnet-20240229
    context_config:
      max_turns: 12
      max_tokens: 5000
      reduction_mode: truncation
  
  # 国产模型
  - display_name: proxy2/qwen-plus
    provider_name: proxy2
    actual_model_name: qwen-plus
    context_config:
      max_turns: 10
      max_tokens: 4000
      reduction_mode: truncation
```

### 示例 3：成本优化配置

针对成本敏感的场景，使用激进的上下文缩减策略。

```yaml
system:
  port: 8000
  log_level: INFO
  session_ttl: 1800  # 30 分钟

storage:
  type: memory

context:
  default_max_turns: 5   # 只保留 5 轮对话
  default_max_tokens: 2000
  default_reduction_mode: truncation

providers:
  - name: openai
    base_url: https://api.openai.com/v1
    api_key: ${OPENAI_API_KEY}
    timeout: 30
    models:
      - gpt-3.5-turbo

model_mappings:
  - display_name: openai/gpt-3.5-turbo
    provider_name: openai
    actual_model_name: gpt-3.5-turbo
    context_config:
      max_turns: 5
      max_tokens: 2000
      reduction_mode: truncation
```

---

## 最佳实践

### 1. 安全性

- ✅ **使用环境变量存储 API 密钥**，不要硬编码在配置文件中
- ✅ **不要提交 `.env` 文件到版本控制**，添加到 `.gitignore`
- ✅ **定期轮换 API 密钥**
- ✅ **生产环境使用 HTTPS**
- ✅ **限制配置文件的访问权限**

### 2. 性能优化

- ✅ **生产环境使用 Redis** 存储，支持多实例部署
- ✅ **根据模型能力设置合理的 `max_tokens`**
- ✅ **为高频使用的模型设置较短的 `session_ttl`**
- ✅ **使用 `truncation` 模式以获得最快响应**
- ✅ **合理设置 `timeout` 值**，避免长时间等待

### 3. 成本控制

- ✅ **使用 `truncation` 或 `sliding_window` 减少 Token 使用**
- ✅ **为昂贵的模型设置更激进的缩减策略**
- ✅ **使用便宜的模型进行摘要**（如用 gpt-3.5-turbo 摘要 gpt-4 对话）
- ✅ **监控日志中的 Token 使用情况**
- ✅ **根据实际使用调整 `max_turns` 和 `max_tokens`**

### 4. 可维护性

- ✅ **使用清晰的命名空间**（provider/model-name）
- ✅ **为每个提供商添加注释说明**
- ✅ **保持配置文件的可读性**，适当使用空行和注释
- ✅ **文档化自定义的摘要提示词**
- ✅ **版本控制配置文件模板**（不含敏感信息）

### 5. 监控和调试

- ✅ **开发环境使用 `DEBUG` 日志级别**
- ✅ **生产环境使用 `INFO` 或 `WARNING` 级别**
- ✅ **定期检查 `context_reduction` 事件**，评估策略效果
- ✅ **监控 `provider_error` 事件**，及时发现问题
- ✅ **使用 `jq` 等工具解析 JSON 日志**

### 6. 测试

- ✅ **修改配置后运行 `python test_manual.py`** 验证
- ✅ **测试所有配置的提供商和模型**
- ✅ **验证环境变量正确加载**
- ✅ **测试上下文缩减策略是否按预期工作**

---

## 配置验证

### 手动验证

```bash
# 1. 验证 YAML 语法
python -c "import yaml; yaml.safe_load(open('config/config.yaml'))"

# 2. 运行测试脚本
python test_manual.py

# 3. 检查环境变量
echo $OPENAI_API_KEY

# 4. 启动服务并检查日志
python -m src.main
```

### 常见配置错误

| 错误 | 原因 | 解决方案 |
|------|------|----------|
| `Configuration loading failed` | YAML 语法错误 | 检查缩进和格式 |
| `Provider 'xxx' not found` | provider_name 不存在 | 确保在 providers 中定义 |
| `Model 'xxx' not found` | 模型未在 provider.models 中列出 | 添加到 models 列表 |
| `Environment variable not set` | 环境变量未定义 | 检查 .env 文件 |
| `Redis connection failed` | Redis 未运行或 URL 错误 | 启动 Redis 或检查 URL |

---

## 高级配置

### 自定义日志格式

虽然日志格式是固定的 JSON，但可以通过 `log_level` 控制详细程度：

```yaml
system:
  log_level: DEBUG  # 开发：详细日志
  # log_level: INFO   # 生产：标准日志
  # log_level: WARNING  # 生产：仅警告和错误
```

### 多环境配置

为不同环境创建不同的配置文件：

```bash
config/
  ├── config.yaml           # 默认配置
  ├── config.dev.yaml       # 开发环境
  ├── config.staging.yaml   # 测试环境
  └── config.prod.yaml      # 生产环境
```

通过环境变量指定：
```bash
export MIDDLEWARE_CONFIG_PATH=config/config.prod.yaml
python -m src.main
```

### 动态配置更新

当前版本不支持热更新，修改配置后需要重启服务：

```bash
# Docker
docker-compose restart middleware

# 本地
# 停止服务（Ctrl+C）然后重新启动
python -m src.main
```

---

## 获取帮助

如果在配置过程中遇到问题：

1. 查看 [快速开始.md](快速开始.md) 获取基础配置指导
2. 查看 [README.md](README.md) 获取完整文档
3. 运行 `python test_manual.py` 验证配置
4. 检查日志中的错误消息
5. 参考本文档的配置示例

---

**配置完成后，运行测试验证一切正常！** ✅

```bash
python test_manual.py
```
